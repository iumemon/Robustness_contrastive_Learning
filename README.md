
# [Robustness of Contrastive Learning on Multilingual Font Style Classification Using Various Contrastive Loss Functions](https://www.mdpi.com/2076-3417/13/6/3635)
## Abstract
Font is a crucial design aspect, however, classifying fonts is challenging compared with that of other natural objects, as fonts differ from images. This paper presents the application of contrastive learning in font style classification. We conducted various experiments to demonstrate the robustness of contrastive image representation learning. First, we built a multilingual synthetic dataset for Chinese, English, and Korean fonts. Next, we trained the model using various contrastive loss functions, i.e., normalized temperature scaled cross-entropy loss, triplet loss, and supervised contrastive loss. We made some explicit changes to the approach of applying contrastive learning in the domain of font style classification by not applying any image augmentation. We compared the results with those of a fully supervised approach and achieved comparable results using contrastive learning with fewer annotated images and a smaller number of training epochs. In addition, we also evaluated the effect of applying different contrastive loss functions on training



## Triplet Loss Overview
<img src="images/triplet overview.png" width="700"/>

# Results
## t_SNE Projections
<img src="images/t_SNE Projections.png" width="600"/>

## Similar Images
<img src="images/similar images.png" width="600"/>
